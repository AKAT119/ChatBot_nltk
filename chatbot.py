# -*- coding: utf-8 -*-
"""ChatBot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10lmkjQQ08ZV__vH6ZAx4pp0xhXGRkh6t
"""

import numpy as np
import string 
import nltk 
import random

f =  open('/content/data.txt', 'r', errors='ignored')
raw_doc = f.read()

raw_doc

raw_doc =  raw_doc.lower()
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

raw_doc

sentence_tokens =  nltk.sent_tokenize(raw_doc)
word_tokenze =  nltk.word_tokenize(raw_doc)

sentence_tokens

word_tokenze

word_tokenze[:5]

"""# Text preprocessing"""

from nltk.stem import WordNetLemmatizer
  
lemmer = WordNetLemmatizer()
def LemTokens(tokens):
    return [lemmer.lemmatize(token) for token in tokens]

remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)

def LemNormalize(text):
    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

greeting_inputs = ["Hi", "How are you?","What's up?!", "Hello","Hey", "How's it going?"]
greeting_responses = ["Hi", "Alright!", "Fine", "Hey there!", "Hey", "It's great to have you here!"]

def greet(sentence):
  for word in sentence.split():
    if word.lower() in greeting_inputs:
      return random.choice(greeting_responses)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def response(user_response):
  robo1_response= ''
  TfidfVec= TfidfVectorizer(stop_words="english")
  Tfidf= TfidfVec.fit_transform(sentence_tokens)
  vals = cosine_similarity(Tfidf[-1], Tfidf)
  idx =  vals.argsort()[0][-2]
  flat= vals.flatten()
  flat.sort()
  req_tfidf = flat[-2]
  if(req_tfidf == 0):
    robo1_response = robo1_response +"I am sorry, I am not able to unsersatnd you!"
    return robo1_response
  else:
    robo1_response =  robo1_response +sentence_tokens[idx]
    return robo1_response

"""FlowCaht"""

flag = True
print("Hi, I am a learning Bot,start your text after greating ti me, for ending conversation print bye!")
while(flag == True):
  user_response = input()
  user_response =  user_response.lower()
  if (user_response != 'bye'):
    if (user_response == 'thank you' or user_response == 'thanks'):
      flag= False
      print('Bot: you are welcome!')
    else:
      if (greet(user_response) != None):
        print('Bot'+ greet(user_response))
      else:
        sentence_tokens.append(user_response)
        word_tokens =word_tokenze + nltk.word_tokenize(user_response)
        final_words = list(set(word_tokens))
        print('Bot: ', end = '')
        print(response(user_response))
        sentence_tokens.remove(user_response)
  else:
    flag= False
    print("Bot:  goodbye!")